## wavsearch ðŸ”–ðŸŽ§

### A simple audio search/retrieval library. (wip)
This is the audio version of [ripple_net](https://github.com/kelechi-c/ripple_net).
It's meant to be an **_neural_ encoded** version of [Shazam](https://www.shazam.com/), but might just be for small scale/local usage.

#### general info

#### Methodology

#### usage

#### Acknowldgements
- [tinyCLAP: Distilling Contrastive Language-Audio Pretrained models]() 
- [CLAP: Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation]() 
- <a href="https://huggingface.co/laion/larger_clap_music_and_speech"> laion/larger_clap_music_and_speech </a> model by LAION.
- <a href="https://huggingface.co/fpaissan/tinyCLAP"> fpaissan/tinyCLAP: </a> distilled CLAP model by <a href="https://huggingface.co/fpaissan/">fpaissan </a> .

```bibtex
@misc{https://doi.org/10.48550/arxiv.2211.06687,
  doi = {10.48550/ARXIV.2211.06687},
  url = {https://arxiv.org/abs/2211.06687},
  author = {Wu, Yusong and Chen, Ke and Zhang, Tianyu and Hui, Yuchen and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  keywords = {Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}
```
